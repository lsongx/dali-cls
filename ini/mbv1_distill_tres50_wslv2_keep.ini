[JOB]
; USE_CLUSTER_ID = idcv2
USE_CLUSTER_ID = aliyun
; USE_CLUSTER_EXTRA = 2080ti
; USE_CLUSTER_EXTRA = small
USE_CLUSTER_EXTRA = 
FILE_FOLDER = torch_submit
PODS = 8
WALLTIME = 1
WORKER = 1
PRIORITY = 5
REAP_RUN = 1
; DOCKER_IMAGE = docker.hobot.cc/dlp/mxnet:runtime-cudnn7.3-cuda9.2-centos7
DOCKER_IMAGE = docker.hobot.cc/dlp/mxnet:runtime-cudnn7.4-cuda10.0-centos7
DSCRB = mbv1-res50-distill-wsl-keep-300epoch

[JOB_PARA]
SCRIPT_PATH = train.py

SCRIPTS = \
hdfs dfs -get hdfs://hobot-bigdata/user/liangchen.song/data/conda_lib10_torch14_dali25_mmcv12.tar \
tar xf conda_lib10_torch14_dali25_mmcv12.tar \
cd data \
hdfs dfs -get hdfs://hobot-bigdata/user/liangchen.song/models/resnet50-19c8e357.pth \
echo `date` \
cp /bucket/input/BasicAlgorithm/imagenet/train_orig.rec train_q95.rec \
cp /bucket/input/BasicAlgorithm/imagenet/train_orig.idx train_q95.idx \
cp /bucket/input/BasicAlgorithm/imagenet/val_orig.rec val_q95.rec \
cp /bucket/input/BasicAlgorithm/imagenet/val_orig.idx val_q95.idx \
echo `date` \
cd ..

[SCRIPT_PARA]
data.train_cfg.reader_cfg.path = ./data/train_q95.rec
data.train_cfg.reader_cfg.index_path = ./data/train_q95.idx
data.val_cfg_fast.reader_cfg.path = ./data/val_q95.rec
data.val_cfg_fast.reader_cfg.index_path = ./data/val_q95.idx
data.train_cfg.batch_size = 128
log_config.interval = 500
optimizer.lr = 0.5

config = ./configs/mbv1_distill_tres50_wslv2_keep.py
use_fp16 = 1
seed = 1

[PARA_DESRB]
b = data.train_cfg.batch_size
l = optimizer.lr
fp16 = use_fp16
